{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ICI ca test de recup des infos sur nba.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver #/!\\ version :4.5.0\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a constant for the url\n",
    "NBA_PLAYERS_STATS_URL = 'https://www.nba.com/stats/alltime-leaders'\n",
    "NBA_PLAYERS_INFO_URL = 'https://www.nba.com/players'\n",
    "NBA_PLAYERS_AGILITY_URL = 'https://www.nba.com/stats/draft/combine-strength-agility'\n",
    "\n",
    "# path to the file containing the chrome driver\n",
    "CHROME_DRIVER_PATH = './chromedriver.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Browser functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting the browser.\n",
    "def startBrowser():\n",
    "    s=Service(CHROME_DRIVER_PATH)\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options = Options()\n",
    "    # options.add_argument(\"--headless\")\n",
    "    return  webdriver.Chrome(service=s, options=options)\n",
    "\n",
    "# Checking if the browser is closed.\n",
    "def isBrowserClosed(browser):\n",
    "    isbrowserClosed = False\n",
    "    try:\n",
    "        webdriver.title\n",
    "    except:\n",
    "        isbrowserClosed = True\n",
    "    return isbrowserClosed\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertion functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert height in df to cm\n",
    "def convertHeightToCm(height):\n",
    "    height = re.findall(r'\\d+-\\d+', height)\n",
    "    if len(height) == 0:\n",
    "        return 0\n",
    "\n",
    "    feet = int(height[0].split('-')[0])\n",
    "    inches = int(height[0].split('-')[1])\n",
    "    return (feet * 12 + inches) * 2.54\n",
    "\n",
    "#convert weight in df to kg\n",
    "def convertWeightToKg(weight):\n",
    "    weight = re.findall(r'\\d+', weight)\n",
    "    if(len(weight) == 0):\n",
    "        return 0\n",
    "    return float(weight[0]) * 0.453592\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Scapping functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above code is getting the data from the URL and returning the dataframe.\n",
    "def getDataFromURL(URL):\n",
    "    browser = startBrowser()\n",
    "    #open the url\n",
    "    browser.get(URL)\n",
    "\n",
    "    time.sleep(1)\n",
    "    # accept cookies\n",
    "    browser.find_element(By.CSS_SELECTOR, \"button#onetrust-accept-btn-handler\").click()\n",
    "    time.sleep(5)\n",
    "\n",
    "    if URL == NBA_PLAYERS_INFO_URL: #this is to get infos from all time players\n",
    "        #click on the button to show all players\n",
    "        browser.find_element(By.XPATH, '//*[@id=\"__next\"]/div[2]/div[2]/main/div[2]/section/div/div[2]/div[1]/div[6]').click()\n",
    "        time.sleep(1)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    while browser.find_element(By.CSS_SELECTOR, \"button[title^='Next Page Button']\").is_enabled():\n",
    "        html = browser.page_source\n",
    "        data, headers = getDataFromHTML(html)\n",
    "\n",
    "        df = pd.concat([df, pd.DataFrame(data, columns=headers)], ignore_index=True)\n",
    "\n",
    "        print(\".\", end = '')\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                browser.find_element(By.CSS_SELECTOR, \"button[title^='Next Page Button']\").click()\n",
    "                break\n",
    "            except:\n",
    "                if(isBrowserClosed(browser)):\n",
    "                    return df\n",
    "                else:\n",
    "                    print('not yet clickable')\n",
    "                    continue\n",
    "\n",
    "    html = browser.page_source\n",
    "    data, headers = getDataFromHTML(html)\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(data, columns=headers)], ignore_index=True)\n",
    "\n",
    "    print(\".\", end = '')\n",
    "\n",
    "    #close the browser\n",
    "    browser.quit()\n",
    "    #return the dataframe\n",
    "    return df\n",
    "\n",
    "def getDataAgilityFromURL(URL, startYear, endYear):\n",
    "    browser = startBrowser()\n",
    "    #open the url\n",
    "    browser.get(URL)\n",
    "\n",
    "    time.sleep(1)\n",
    "    # accept cookies\n",
    "    browser.find_element(By.CSS_SELECTOR, \"button#onetrust-accept-btn-handler\").click()\n",
    "    time.sleep(5)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    currentYear = startYear\n",
    "\n",
    "    while currentYear <= endYear:\n",
    "        #select the year\n",
    "        # send key arrow down\n",
    "        browser.find_element(By.CSS_SELECTOR, \"select.DropDown_select__4pIg9\").send_keys(Keys.ARROW_DOWN)\n",
    "        time.sleep(1)\n",
    "\n",
    "        html = browser.page_source\n",
    "        data, headers = getDataFromHTML(html)\n",
    "\n",
    "        df = pd.concat([df, pd.DataFrame(data, columns=headers)], ignore_index=True)\n",
    "\n",
    "        print(\".\", end = '')\n",
    "\n",
    "        currentYear += 1\n",
    "\n",
    "    #close the browser\n",
    "    browser.quit()\n",
    "    #return the dataframe\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "#Parsing the html and returning the data and headers.\n",
    "def getDataFromHTML(html):\n",
    "    #parse the html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    #find the table with class Crom_table__p1iZz or players-list\n",
    "    table = soup.find('table', attrs = {'class' : ['Crom_table__p1iZz','players-list']})\n",
    "    #get the table headers\n",
    "    headers = [header.text for header in table.findAll('th', attrs = {'hidden': None})]\n",
    "    #get the table rows\n",
    "    rows = table.find_all('tr')\n",
    "    #get the table data\n",
    "    data = [[td.text for td in rows[i].find_all('td')] for i in range(len(rows))]\n",
    "    data = [row for row in data if row != []]#they is an empty at the start idk why but yes\n",
    "\n",
    "    return data, headers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get stats from all players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start of the scrapping\n",
      "................................................................................................\n",
      "end of the scrapping\n",
      "\n",
      "\n",
      "saving the dataframe to a csv file...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"start of the scrapping\")\n",
    "df = getDataFromURL(NBA_PLAYERS_STATS_URL)\n",
    "print(\"\\nend of the scrapping\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"saving the dataframe to a csv file...\")\n",
    "df.to_csv('nbaPlayersAllTimesStatsData.csv', index = False)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataframe has 4771 rows and 23 columns\n"
     ]
    }
   ],
   "source": [
    "#get nb rows and nb columns\n",
    "print(\"the dataframe has\", df.shape[0], \"rows and\", df.shape[1], \"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Info from all players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start of the scrapping\n",
      ".................................................................................................\n",
      "end of the scrapping\n",
      "\n",
      "\n",
      "Converting height and weight to cm and kg...done\n",
      "\n",
      "\n",
      "saving the dataframe to a csv file...done\n"
     ]
    }
   ],
   "source": [
    "print(\"start of the scrapping\")\n",
    "df = getDataFromURL(NBA_PLAYERS_INFO_URL)\n",
    "print(\"\\nend of the scrapping\\n\\n\")\n",
    "\n",
    "print(\"Converting height and weight to cm and kg...\", end = '')\n",
    "#convert height in df to cm\n",
    "df['Height'] = df['Height'].apply(convertHeightToCm)\n",
    "# convert weight in df to kg\n",
    "df['Weight'] = df['Weight'].apply(convertWeightToKg)\n",
    "print(\"done\\n\\n\")\n",
    "\n",
    "print(\"saving the dataframe to a csv file...\", end = '')\n",
    "df.to_csv('nbaPlayersAllTimesInfo.csv', index = False)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataframe has 4804 rows and 8 columns\n"
     ]
    }
   ],
   "source": [
    "#get nb rows and nb columns\n",
    "print(\"the dataframe has\", df.shape[0], \"rows and\", df.shape[1], \"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get player Agility infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start of the scrapping\n",
      "........................\n",
      "end of the scrapping\n",
      "\n",
      "\n",
      "saving the dataframe to a csv file...done\n"
     ]
    }
   ],
   "source": [
    "print(\"start of the scrapping\")\n",
    "df = getDataAgilityFromURL(NBA_PLAYERS_AGILITY_URL, 2000, 2023)\n",
    "print(\"\\nend of the scrapping\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"saving the dataframe to a csv file...\", end = '')\n",
    "df.to_csv('nbaPlayersAllTimesAgilityData.csv', index = False)\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataframe has 1605 rows and 8 columns\n"
     ]
    }
   ],
   "source": [
    "print(\"the dataframe has\", df.shape[0], \"rows and\", df.shape[1], \"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# /!\\TEST MERGE DATA TEST/!\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'nbaplayerssAllTimesInfo.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [13], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m dfStats \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mnbaPlayersAllTimesStatsData.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[39m#load the data\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m dfInfo \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mnbaplayerssAllTimesInfo.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mformalize\u001b[39m(x):\n\u001b[0;32m      8\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(x) \u001b[39m==\u001b[39m \u001b[39mstr\u001b[39m:\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    312\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    313\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    314\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    315\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(inspect\u001b[39m.\u001b[39mcurrentframe()),\n\u001b[0;32m    316\u001b[0m     )\n\u001b[1;32m--> 317\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1729\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1727\u001b[0m     is_text \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1728\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1729\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1730\u001b[0m     f,\n\u001b[0;32m   1731\u001b[0m     mode,\n\u001b[0;32m   1732\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1733\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1734\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1735\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1736\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1737\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1738\u001b[0m )\n\u001b[0;32m   1739\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1740\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\io\\common.py:857\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    853\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    855\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    856\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    858\u001b[0m             handle,\n\u001b[0;32m    859\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    860\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    861\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    862\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    863\u001b[0m         )\n\u001b[0;32m    864\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    865\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    866\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'nbaplayerssAllTimesInfo.csv'"
     ]
    }
   ],
   "source": [
    "#load the data\n",
    "dfStats = pd.read_csv('nbaPlayersAllTimesStatsData.csv')\n",
    "\n",
    "#load the data\n",
    "dfInfo = pd.read_csv('nbaplayerssAllTimesInfo.csv')\n",
    "\n",
    "def formalize(x):\n",
    "    if type(x) == str:\n",
    "        return x.replace(' ', '')\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "#in dfStart remove space in PLAYER columnx\n",
    "dfStats['PLAYER'] = dfStats['PLAYER'].apply(formalize)\n",
    "\n",
    "\n",
    "# merge the two dataframes on Player and PLAYER columns if exist in both\n",
    "df = pd.merge(dfStats, dfInfo, left_on='PLAYER', right_on='Player', how='left')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
