{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ICI ca test de recup des infos sur nba.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver #/!\\ version :4.5.0\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "#create a constant for the url\n",
    "NBA_PLAYERS_STATS_URL = 'https://www.nba.com/stats/alltime-leaders'\n",
    "NBA_PLAYERS_INFO_URL = 'https://www.nba.com/players'\n",
    "NBA_PLAYERS_AGILITY_URL = 'https://www.nba.com/stats/draft/combine-strength-agility'\n",
    "\n",
    "# path to the file containing the chrome driver\n",
    "CHROME_DRIVER_PATH = \"./chromedriver.exe\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Browser functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting the browser.\n",
    "def startBrowser():\n",
    "    s=Service(CHROME_DRIVER_PATH)\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options = Options()\n",
    "    # options.add_argument(\"--headless\")\n",
    "    return  browser.webdriver.Chrome()\n",
    "\n",
    "# Checking if the browser is closed.\n",
    "def isBrowserClosed(browser):\n",
    "    isbrowserClosed = False\n",
    "    try:\n",
    "        webdriver.title\n",
    "    except:\n",
    "        isbrowserClosed = True\n",
    "    return isbrowserClosed\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertion functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert height in df to cm\n",
    "def convertHeightToCm(height):\n",
    "    height = re.findall(r'\\d+-\\d+', height)\n",
    "    if len(height) == 0:\n",
    "        return 0\n",
    "\n",
    "    feet = int(height[0].split('-')[0])\n",
    "    inches = int(height[0].split('-')[1])\n",
    "    return (feet * 12 + inches) * 2.54\n",
    "\n",
    "#convert weight in df to kg\n",
    "def convertWeightToKg(weight):\n",
    "    weight = re.findall(r'\\d+', weight)\n",
    "    if(len(weight) == 0):\n",
    "        return 0\n",
    "    return float(weight[0]) * 0.453592\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Scapping functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above code is getting the data from the URL and returning the dataframe.\n",
    "def getDataFromURL(URL):\n",
    "    browser = startBrowser()\n",
    "    #open the url\n",
    "    browser.get(URL)\n",
    "\n",
    "    time.sleep(1)\n",
    "    # accept cookies\n",
    "    browser.find_element(By.CSS_SELECTOR, \"button#onetrust-accept-btn-handler\").click()\n",
    "    time.sleep(5)\n",
    "\n",
    "    if URL == NBA_PLAYERS_INFO_URL: #this is to get infos from all time players\n",
    "        #click on the button to show all players\n",
    "        browser.find_element(By.XPATH, '//*[@id=\"__next\"]/div[2]/div[2]/main/div[2]/section/div/div[2]/div[1]/div[6]').click()\n",
    "        time.sleep(1)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    while browser.find_element(By.CSS_SELECTOR, \"button[title^='Next Page Button']\").is_enabled():\n",
    "        html = browser.page_source\n",
    "        data, headers = getDataFromHTML(html)\n",
    "\n",
    "        df = pd.concat([df, pd.DataFrame(data, columns=headers)], ignore_index=True)\n",
    "\n",
    "        print(\".\", end = '')\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                browser.find_element(By.CSS_SELECTOR, \"button[title^='Next Page Button']\").click()\n",
    "                break\n",
    "            except:\n",
    "                if(isBrowserClosed(browser)):\n",
    "                    return df\n",
    "                else:\n",
    "                    print('not yet clickable')\n",
    "                    continue\n",
    "\n",
    "    html = browser.page_source\n",
    "    data, headers = getDataFromHTML(html)\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(data, columns=headers)], ignore_index=True)\n",
    "\n",
    "    print(\".\", end = '')\n",
    "\n",
    "    #close the browser\n",
    "    browser.quit()\n",
    "    #return the dataframe\n",
    "    return df\n",
    "\n",
    "def getDataAgilityFromURL(URL, startYear, endYear):\n",
    "    browser = startBrowser()\n",
    "    #open the url\n",
    "    browser.get(URL)\n",
    "\n",
    "    time.sleep(1)\n",
    "    # accept cookies\n",
    "    browser.find_element(By.CSS_SELECTOR, \"button#onetrust-accept-btn-handler\").click()\n",
    "    time.sleep(5)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    currentYear = startYear\n",
    "\n",
    "    while currentYear <= endYear:\n",
    "        #select the year\n",
    "        # send key arrow down\n",
    "        browser.find_element(By.CSS_SELECTOR, \"select.DropDown_select__4pIg9\").send_keys(Keys.ARROW_DOWN)\n",
    "        time.sleep(1)\n",
    "\n",
    "        html = browser.page_source\n",
    "        data, headers = getDataFromHTML(html)\n",
    "\n",
    "        df = pd.concat([df, pd.DataFrame(data, columns=headers)], ignore_index=True)\n",
    "\n",
    "        print(\".\", end = '')\n",
    "\n",
    "        currentYear += 1\n",
    "\n",
    "    #close the browser\n",
    "    browser.quit()\n",
    "    #return the dataframe\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "#Parsing the html and returning the data and headers.\n",
    "def getDataFromHTML(html):\n",
    "    #parse the html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    #find the table with class Crom_table__p1iZz or players-list\n",
    "    table = soup.find('table', attrs = {'class' : ['Crom_table__p1iZz','players-list']})\n",
    "    #get the table headers\n",
    "    headers = [header.text for header in table.findAll('th', attrs = {'hidden': None})]\n",
    "    #get the table rows\n",
    "    rows = table.find_all('tr')\n",
    "    #get the table data\n",
    "    data = [[td.text for td in rows[i].find_all('td')] for i in range(len(rows))]\n",
    "    data = [row for row in data if row != []]#they is an empty at the start idk why but yes\n",
    "\n",
    "    return data, headers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get stats from all players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start of the scrapping\n",
      "................................................................................................\n",
      "end of the scrapping\n",
      "\n",
      "\n",
      "saving the dataframe to a csv file...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"start of the scrapping\")\n",
    "df = getDataFromURL(NBA_PLAYERS_STATS_URL)\n",
    "print(\"\\nend of the scrapping\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"saving the dataframe to a csv file...\")\n",
    "df.to_csv('nbaPlayersAllTimesStatsData.csv', index = False)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataframe has 4771 rows and 23 columns\n"
     ]
    }
   ],
   "source": [
    "#get nb rows and nb columns\n",
    "print(\"the dataframe has\", df.shape[0], \"rows and\", df.shape[1], \"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Info from all players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start of the scrapping\n",
      ".................................................................................................\n",
      "end of the scrapping\n",
      "\n",
      "\n",
      "Converting height and weight to cm and kg...done\n",
      "\n",
      "\n",
      "saving the dataframe to a csv file...done\n"
     ]
    }
   ],
   "source": [
    "print(\"start of the scrapping\")\n",
    "df = getDataFromURL(NBA_PLAYERS_INFO_URL)\n",
    "print(\"\\nend of the scrapping\\n\\n\")\n",
    "\n",
    "print(\"Converting height and weight to cm and kg...\", end = '')\n",
    "#convert height in df to cm\n",
    "df['Height'] = df['Height'].apply(convertHeightToCm)\n",
    "# convert weight in df to kg\n",
    "df['Weight'] = df['Weight'].apply(convertWeightToKg)\n",
    "print(\"done\\n\\n\")\n",
    "\n",
    "print(\"saving the dataframe to a csv file...\", end = '')\n",
    "df.to_csv('nbaPlayersAllTimesInfo.csv', index = False)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataframe has 4804 rows and 8 columns\n"
     ]
    }
   ],
   "source": [
    "#get nb rows and nb columns\n",
    "print(\"the dataframe has\", df.shape[0], \"rows and\", df.shape[1], \"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get player Agility infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start of the scrapping\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mstart of the scrapping\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m df \u001b[39m=\u001b[39m getDataAgilityFromURL(NBA_PLAYERS_AGILITY_URL, \u001b[39m2000\u001b[39m, \u001b[39m2023\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mend of the scrapping\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39msaving the dataframe to a csv file...\u001b[39m\u001b[39m\"\u001b[39m, end \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn [6], line 51\u001b[0m, in \u001b[0;36mgetDataAgilityFromURL\u001b[1;34m(URL, startYear, endYear)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetDataAgilityFromURL\u001b[39m(URL, startYear, endYear):\n\u001b[1;32m---> 51\u001b[0m     browser \u001b[39m=\u001b[39m startBrowser()\n\u001b[0;32m     52\u001b[0m     \u001b[39m#open the url\u001b[39;00m\n\u001b[0;32m     53\u001b[0m     browser\u001b[39m.\u001b[39mget(URL)\n",
      "Cell \u001b[1;32mIn [30], line 7\u001b[0m, in \u001b[0;36mstartBrowser\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m options \u001b[39m=\u001b[39m Options()\n\u001b[0;32m      6\u001b[0m \u001b[39m# options.add_argument(\"--headless\")\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[39mreturn\u001b[39;00m  webdriver\u001b[39m.\u001b[39;49mChrome(service\u001b[39m=\u001b[39;49ms, options\u001b[39m=\u001b[39;49moptions)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\selenium\\webdriver\\chrome\\webdriver.py:69\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[1;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, service, keep_alive)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m service:\n\u001b[0;32m     67\u001b[0m     service \u001b[39m=\u001b[39m Service(executable_path, port, service_args, service_log_path)\n\u001b[1;32m---> 69\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(DesiredCapabilities\u001b[39m.\u001b[39;49mCHROME[\u001b[39m'\u001b[39;49m\u001b[39mbrowserName\u001b[39;49m\u001b[39m'\u001b[39;49m], \u001b[39m\"\u001b[39;49m\u001b[39mgoog\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     70\u001b[0m                  port, options,\n\u001b[0;32m     71\u001b[0m                  service_args, desired_capabilities,\n\u001b[0;32m     72\u001b[0m                  service_log_path, service, keep_alive)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\selenium\\webdriver\\chromium\\webdriver.py:89\u001b[0m, in \u001b[0;36mChromiumDriver.__init__\u001b[1;34m(self, browser_name, vendor_prefix, port, options, service_args, desired_capabilities, service_log_path, service, keep_alive)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mservice cannot be None\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     88\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mservice \u001b[39m=\u001b[39m service\n\u001b[1;32m---> 89\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mservice\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[0;32m     93\u001b[0m         command_executor\u001b[39m=\u001b[39mChromiumRemoteConnection(\n\u001b[0;32m     94\u001b[0m             remote_server_addr\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mservice\u001b[39m.\u001b[39mservice_url,\n\u001b[0;32m     95\u001b[0m             browser_name\u001b[39m=\u001b[39mbrowser_name, vendor_prefix\u001b[39m=\u001b[39mvendor_prefix,\n\u001b[0;32m     96\u001b[0m             keep_alive\u001b[39m=\u001b[39mkeep_alive, ignore_proxy\u001b[39m=\u001b[39m_ignore_proxy),\n\u001b[0;32m     97\u001b[0m         options\u001b[39m=\u001b[39moptions)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\selenium\\webdriver\\common\\service.py:71\u001b[0m, in \u001b[0;36mService.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     69\u001b[0m     cmd \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath]\n\u001b[0;32m     70\u001b[0m     cmd\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_line_args())\n\u001b[1;32m---> 71\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39;49mPopen(cmd, env\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv,\n\u001b[0;32m     72\u001b[0m                                     close_fds\u001b[39m=\u001b[39;49msystem() \u001b[39m!=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mWindows\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     73\u001b[0m                                     stdout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlog_file,\n\u001b[0;32m     74\u001b[0m                                     stderr\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlog_file,\n\u001b[0;32m     75\u001b[0m                                     stdin\u001b[39m=\u001b[39;49mPIPE,\n\u001b[0;32m     76\u001b[0m                                     creationflags\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreationflags)\n\u001b[0;32m     77\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\subprocess.py:969\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[0;32m    965\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_mode:\n\u001b[0;32m    966\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[0;32m    967\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m--> 969\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0;32m    970\u001b[0m                         pass_fds, cwd, env,\n\u001b[0;32m    971\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[0;32m    972\u001b[0m                         p2cread, p2cwrite,\n\u001b[0;32m    973\u001b[0m                         c2pread, c2pwrite,\n\u001b[0;32m    974\u001b[0m                         errread, errwrite,\n\u001b[0;32m    975\u001b[0m                         restore_signals,\n\u001b[0;32m    976\u001b[0m                         gid, gids, uid, umask,\n\u001b[0;32m    977\u001b[0m                         start_new_session)\n\u001b[0;32m    978\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m    979\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m    980\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mfilter\u001b[39m(\u001b[39mNone\u001b[39;00m, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdin, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr)):\n",
      "File \u001b[1;32mc:\\Python310\\lib\\subprocess.py:1378\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1376\u001b[0m     args \u001b[39m=\u001b[39m list2cmdline([args])\n\u001b[0;32m   1377\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1378\u001b[0m     args \u001b[39m=\u001b[39m list2cmdline(args)\n\u001b[0;32m   1380\u001b[0m \u001b[39mif\u001b[39;00m executable \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1381\u001b[0m     executable \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mfsdecode(executable)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\subprocess.py:561\u001b[0m, in \u001b[0;36mlist2cmdline\u001b[1;34m(seq)\u001b[0m\n\u001b[0;32m    559\u001b[0m result \u001b[39m=\u001b[39m []\n\u001b[0;32m    560\u001b[0m needquote \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m--> 561\u001b[0m \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m \u001b[39mmap\u001b[39m(os\u001b[39m.\u001b[39mfsdecode, seq):\n\u001b[0;32m    562\u001b[0m     bs_buf \u001b[39m=\u001b[39m []\n\u001b[0;32m    564\u001b[0m     \u001b[39m# Add a space to separate this argument from the others\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\os.py:822\u001b[0m, in \u001b[0;36m_fscodec.<locals>.fsdecode\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m    816\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfsdecode\u001b[39m(filename):\n\u001b[0;32m    817\u001b[0m     \u001b[39m\"\"\"Decode filename (an os.PathLike, bytes, or str) from the filesystem\u001b[39;00m\n\u001b[0;32m    818\u001b[0m \u001b[39m    encoding with 'surrogateescape' error handler, return str unchanged. On\u001b[39;00m\n\u001b[0;32m    819\u001b[0m \u001b[39m    Windows, use 'strict' error handler if the file system encoding is\u001b[39;00m\n\u001b[0;32m    820\u001b[0m \u001b[39m    'mbcs' (which is the default encoding).\u001b[39;00m\n\u001b[0;32m    821\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 822\u001b[0m     filename \u001b[39m=\u001b[39m fspath(filename)  \u001b[39m# Does type-checking of `filename`.\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(filename, \u001b[39mbytes\u001b[39m):\n\u001b[0;32m    824\u001b[0m         \u001b[39mreturn\u001b[39;00m filename\u001b[39m.\u001b[39mdecode(encoding, errors)\n",
      "\u001b[1;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "print(\"start of the scrapping\")\n",
    "df = getDataAgilityFromURL(NBA_PLAYERS_AGILITY_URL, 2000, 2023)\n",
    "print(\"\\nend of the scrapping\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"saving the dataframe to a csv file...\", end = '')\n",
    "df.to_csv('nbaPlayersAllTimesAgilityData.csv', index = False)\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataframe has 1605 rows and 8 columns\n"
     ]
    }
   ],
   "source": [
    "print(\"the dataframe has\", df.shape[0], \"rows and\", df.shape[1], \"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# /!\\TEST MERGE DATA TEST/!\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'nbaplayerssAllTimesInfo.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [13], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m dfStats \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mnbaPlayersAllTimesStatsData.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[39m#load the data\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m dfInfo \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mnbaplayerssAllTimesInfo.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mformalize\u001b[39m(x):\n\u001b[0;32m      8\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(x) \u001b[39m==\u001b[39m \u001b[39mstr\u001b[39m:\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    312\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    313\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    314\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    315\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(inspect\u001b[39m.\u001b[39mcurrentframe()),\n\u001b[0;32m    316\u001b[0m     )\n\u001b[1;32m--> 317\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1729\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1727\u001b[0m     is_text \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1728\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1729\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1730\u001b[0m     f,\n\u001b[0;32m   1731\u001b[0m     mode,\n\u001b[0;32m   1732\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1733\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1734\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1735\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1736\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1737\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1738\u001b[0m )\n\u001b[0;32m   1739\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1740\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\io\\common.py:857\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    853\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    855\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    856\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    858\u001b[0m             handle,\n\u001b[0;32m    859\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    860\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    861\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    862\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    863\u001b[0m         )\n\u001b[0;32m    864\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    865\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    866\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'nbaplayerssAllTimesInfo.csv'"
     ]
    }
   ],
   "source": [
    "#load the data\n",
    "dfStats = pd.read_csv('nbaPlayersAllTimesStatsData.csv')\n",
    "\n",
    "#load the data\n",
    "dfInfo = pd.read_csv('nbaplayerssAllTimesInfo.csv')\n",
    "\n",
    "def formalize(x):\n",
    "    if type(x) == str:\n",
    "        return x.replace(' ', '')\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "#in dfStart remove space in PLAYER columnx\n",
    "dfStats['PLAYER'] = dfStats['PLAYER'].apply(formalize)\n",
    "\n",
    "\n",
    "# merge the two dataframes on Player and PLAYER columns if exist in both\n",
    "df = pd.merge(dfStats, dfInfo, left_on='PLAYER', right_on='Player', how='left')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
