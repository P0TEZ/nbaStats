{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ICI ca test de recup des infos sur nba.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver #/!\\ version :4.5.0\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a constant for the url\n",
    "NBA_PLAYERS_STATS_URL = 'https://www.nba.com/stats/alltime-leaders'\n",
    "NBA_PLAYERS_INFO_URL = 'https://www.nba.com/players'\n",
    "\n",
    "# path to the file containing the chrome driver\n",
    "CHROME_DRIVER_PATH = 'C:/chromedriver.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful functions for browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting the browser.\n",
    "def startBrowser():\n",
    "    s=Service(CHROME_DRIVER_PATH)\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")\n",
    "    return  webdriver.Chrome(service=s, options=options)\n",
    "\n",
    "# Checking if the browser is closed.\n",
    "def isBrowserClosed(browser):\n",
    "    isbrowserClosed = False\n",
    "    try:\n",
    "        webdriver.title\n",
    "    except:\n",
    "        isbrowserClosed = True\n",
    "    return isbrowserClosed\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get stats from all players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above code is getting the data from the URL and returning the dataframe.\n",
    "def getDataFromURL(URL):\n",
    "    browser = startBrowser()\n",
    "    #open the url\n",
    "    browser.get(URL)\n",
    "\n",
    "    # accept cookies\n",
    "    browser.find_element(By.CSS_SELECTOR, \"button#onetrust-accept-btn-handler\").click()\n",
    "    time.sleep(10)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    while browser.find_element(By.CSS_SELECTOR, \"button[title^='Next Page Button']\").is_enabled():\n",
    "        html = browser.page_source\n",
    "        data, headers = getDataFromHTML(html)\n",
    "\n",
    "        df = pd.concat([df, pd.DataFrame(data, columns=headers)], ignore_index=True)\n",
    "\n",
    "        print(\".\", end = '')\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                browser.find_element(By.CSS_SELECTOR, \"button[title^='Next Page Button']\").click()\n",
    "                break\n",
    "            except:\n",
    "                if(isBrowserClosed(browser)):\n",
    "                    return df\n",
    "                else:\n",
    "                    print('not yet clickable')\n",
    "                    continue\n",
    "\n",
    "        html = browser.page_source\n",
    "        data, headers = getDataFromHTML(html)\n",
    "\n",
    "        df = pd.concat([df, pd.DataFrame(data, columns=headers)], ignore_index=True)\n",
    "\n",
    "        print(\".\", end = '')\n",
    "\n",
    "    #close the browser\n",
    "    browser.quit()\n",
    "    #return the dataframe\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "#Parsing the html and returning the data and headers.\n",
    "def getDataFromHTML(html):\n",
    "    #parse the html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    #find the table with class Crom_table__p1iZz or players-list\n",
    "    table = soup.find('table', attrs = {'class' : ['Crom_table__p1iZz','players-list']})\n",
    "    #get the table headers\n",
    "    headers = [header.text for header in table.findAll('th', attrs = {'hidden': None})]\n",
    "    #get the table rows\n",
    "    rows = table.find_all('tr')\n",
    "    #get the table data\n",
    "    data = [[td.text for td in rows[i].find_all('td')] for i in range(len(rows))]\n",
    "    data = [row for row in data if row != []]#they is an empty at the start idk why but yes\n",
    "\n",
    "    return data, headers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save stats in a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start of the scrapping\n",
      "..............................................................................................................................................................................................\n",
      "end of the scrapping\n",
      "\n",
      "\n",
      "saving the dataframe to a csv file...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"start of the scrapping\")\n",
    "df = getDataFromURL(NBA_PLAYERS_STATS_URL)\n",
    "print(\"\\nend of the scrapping\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"saving the dataframe to a csv file...\")\n",
    "df.to_csv('nbaPlayersAllTimesData.csv', index = False)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start of the scrapping\n",
      "....................\n",
      "end of the scrapping\n",
      "\n",
      "\n",
      "Converting height and weight to cm and kg...\n",
      "done\n",
      "\n",
      "\n",
      "saving the dataframe to a csv file...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"start of the scrapping\")\n",
    "df = getDataFromURL(NBA_PLAYERS_INFO_URL)\n",
    "print(\"\\nend of the scrapping\\n\\n\")\n",
    "\n",
    "print(\"Converting height and weight to cm and kg...\", end = '')\n",
    "#convert height in df to cm\n",
    "def convertHeightToCm(height):\n",
    "    feet = int(height.split('-')[0])\n",
    "    inches = int(height.split('-')[1])\n",
    "    return (feet * 12 + inches) * 2.54\n",
    "\n",
    "#convert weight in df to kg\n",
    "def convertWeightToKg(weight):\n",
    "    weight = weight[:-3]\n",
    "    return int(weight) * 0.453592\n",
    "\n",
    "#convert height in df to cm\n",
    "df['Height'] = df['Height'].apply(convertHeightToCm)\n",
    "# convert weight in df to kg\n",
    "df['Weight'] = df['Weight'].apply(convertWeightToKg)\n",
    "print(\"done\\n\\n\")\n",
    "\n",
    "print(\"saving the dataframe to a csv file...\", end = '')\n",
    "df.to_csv('nbaPlayersInfo.csv', index = False)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Player Team Number Position Height   Weight    Last Attended  \\\n",
      "0  PreciousAchiuwa  TOR      5        F    6-8  225 lbs          Memphis   \n",
      "1      StevenAdams  MEM      4        C   6-11  265 lbs       Pittsburgh   \n",
      "2       BamAdebayo  MIA     13      C-F    6-9  255 lbs         Kentucky   \n",
      "3      OchaiAgbaji  UTA     30        G    6-5  215 lbs           Kansas   \n",
      "4      SantiAldama  MEM      7      F-C    7-0  215 lbs  Loyola-Maryland   \n",
      "\n",
      "       Country  \n",
      "0      Nigeria  \n",
      "1  New Zealand  \n",
      "2          USA  \n",
      "3          USA  \n",
      "4        Spain  \n",
      "            Player Team Number Position  Height     Weight    Last Attended  \\\n",
      "0  PreciousAchiuwa  TOR      5        F  203.20  102.05820          Memphis   \n",
      "1      StevenAdams  MEM      4        C  210.82  120.20188       Pittsburgh   \n",
      "2       BamAdebayo  MIA     13      C-F  205.74  115.66596         Kentucky   \n",
      "3      OchaiAgbaji  UTA     30        G  195.58   97.52228           Kansas   \n",
      "4      SantiAldama  MEM      7      F-C  213.36   97.52228  Loyola-Maryland   \n",
      "\n",
      "       Country  \n",
      "0      Nigeria  \n",
      "1  New Zealand  \n",
      "2          USA  \n",
      "3          USA  \n",
      "4        Spain  \n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
