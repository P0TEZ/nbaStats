{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ICI ca test de recup des infos sur nba.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver #/!\\ version :4.5.0\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a constant for the url\n",
    "NBA_PLAYERS_STATS_URL = 'https://www.nba.com/stats/alltime-leaders'\n",
    "NBA_PLAYERS_INFO_URL = 'https://www.nba.com/players'\n",
    "NBA_PLAYERS_AGILITY_URL = 'https://www.nba.com/stats/draft/combine-strength-agility' #TODO\n",
    "\n",
    "# path to the file containing the chrome driver\n",
    "CHROME_DRIVER_PATH = 'C:/chromedriver.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Browser functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting the browser.\n",
    "def startBrowser():\n",
    "    s=Service(CHROME_DRIVER_PATH)\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options = Options()\n",
    "    #options.add_argument(\"--headless\")\n",
    "    return  webdriver.Chrome(service=s, options=options)\n",
    "\n",
    "# Checking if the browser is closed.\n",
    "def isBrowserClosed(browser):\n",
    "    isbrowserClosed = False\n",
    "    try:\n",
    "        webdriver.title\n",
    "    except:\n",
    "        isbrowserClosed = True\n",
    "    return isbrowserClosed\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertion functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert height in df to cm\n",
    "def convertHeightToCm(height):\n",
    "    height = re.findall(r'\\d+-\\d+', height)\n",
    "    if len(height) == 0:\n",
    "        return 0\n",
    "\n",
    "    feet = int(height[0].split('-')[0])\n",
    "    inches = int(height[0].split('-')[1])\n",
    "    return (feet * 12 + inches) * 2.54\n",
    "\n",
    "#convert weight in df to kg\n",
    "def convertWeightToKg(weight):\n",
    "    weight = re.findall(r'\\d+', weight)\n",
    "    if(len(weight) == 0):\n",
    "        return 0\n",
    "    return float(weight[0]) * 0.453592\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Scapping functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above code is getting the data from the URL and returning the dataframe.\n",
    "def getDataFromURL(URL):\n",
    "    browser = startBrowser()\n",
    "    #open the url\n",
    "    browser.get(URL)\n",
    "\n",
    "    time.sleep(1)\n",
    "    # accept cookies\n",
    "    browser.find_element(By.CSS_SELECTOR, \"button#onetrust-accept-btn-handler\").click()\n",
    "    time.sleep(5)\n",
    "\n",
    "    if URL == NBA_PLAYERS_INFO_URL: #this is to get infos from all time players\n",
    "        #click on the button to show all players\n",
    "        browser.find_element(By.XPATH, '//*[@id=\"__next\"]/div[2]/div[2]/main/div[2]/section/div/div[2]/div[1]/div[6]').click()\n",
    "        time.sleep(1)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    while browser.find_element(By.CSS_SELECTOR, \"button[title^='Next Page Button']\").is_enabled():\n",
    "        html = browser.page_source\n",
    "        data, headers = getDataFromHTML(html)\n",
    "\n",
    "        df = pd.concat([df, pd.DataFrame(data, columns=headers)], ignore_index=True)\n",
    "\n",
    "        print(\".\", end = '')\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                browser.find_element(By.CSS_SELECTOR, \"button[title^='Next Page Button']\").click()\n",
    "                break\n",
    "            except:\n",
    "                if(isBrowserClosed(browser)):\n",
    "                    return df\n",
    "                else:\n",
    "                    print('not yet clickable')\n",
    "                    continue\n",
    "\n",
    "    html = browser.page_source\n",
    "    data, headers = getDataFromHTML(html)\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(data, columns=headers)], ignore_index=True)\n",
    "\n",
    "    print(\".\", end = '')\n",
    "\n",
    "    #close the browser\n",
    "    browser.quit()\n",
    "    #return the dataframe\n",
    "    return df\n",
    "\n",
    "def getDataAgilityFromURL(URL, startYear, endYear):\n",
    "    browser = startBrowser()\n",
    "    #open the url\n",
    "    browser.get(URL)\n",
    "\n",
    "    time.sleep(1)\n",
    "    # accept cookies\n",
    "    browser.find_element(By.CSS_SELECTOR, \"button#onetrust-accept-btn-handler\").click()\n",
    "    time.sleep(5)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    currentYear = startYear\n",
    "\n",
    "    while currentYear <= endYear:\n",
    "        #select the year\n",
    "        # send key arrow down\n",
    "        browser.find_element(By.CSS_SELECTOR, \"select.DropDown_select__4pIg9\").send_keys(Keys.ARROW_DOWN)\n",
    "        time.sleep(1)\n",
    "\n",
    "        html = browser.page_source\n",
    "        data, headers = getDataFromHTML(html)\n",
    "\n",
    "        df = pd.concat([df, pd.DataFrame(data, columns=headers)], ignore_index=True)\n",
    "\n",
    "        print(\".\", end = '')\n",
    "\n",
    "        currentYear += 1\n",
    "\n",
    "    #close the browser\n",
    "    browser.quit()\n",
    "    #return the dataframe\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "#Parsing the html and returning the data and headers.\n",
    "def getDataFromHTML(html):\n",
    "    #parse the html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    #find the table with class Crom_table__p1iZz or players-list\n",
    "    table = soup.find('table', attrs = {'class' : ['Crom_table__p1iZz','players-list']})\n",
    "    #get the table headers\n",
    "    headers = [header.text for header in table.findAll('th', attrs = {'hidden': None})]\n",
    "    #get the table rows\n",
    "    rows = table.find_all('tr')\n",
    "    #get the table data\n",
    "    data = [[td.text for td in rows[i].find_all('td')] for i in range(len(rows))]\n",
    "    data = [row for row in data if row != []]#they is an empty at the start idk why but yes\n",
    "\n",
    "    return data, headers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get stats from all players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start of the scrapping\n",
      "................................................................................................\n",
      "end of the scrapping\n",
      "\n",
      "\n",
      "saving the dataframe to a csv file...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"start of the scrapping\")\n",
    "df = getDataFromURL(NBA_PLAYERS_STATS_URL)\n",
    "print(\"\\nend of the scrapping\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"saving the dataframe to a csv file...\")\n",
    "df.to_csv('nbaPlayersAllTimesStatsData.csv', index = False)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataframe has 4770 rows and 23 columns\n"
     ]
    }
   ],
   "source": [
    "#get nb rows and nb columns\n",
    "print(\"the dataframe has\", df.shape[0], \"rows and\", df.shape[1], \"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Info from all players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start of the scrapping\n",
      ".................................................................................................\n",
      "end of the scrapping\n",
      "\n",
      "\n",
      "Converting height and weight to cm and kg...done\n",
      "\n",
      "\n",
      "saving the dataframe to a csv file...done\n"
     ]
    }
   ],
   "source": [
    "print(\"start of the scrapping\")\n",
    "df = getDataFromURL(NBA_PLAYERS_INFO_URL)\n",
    "print(\"\\nend of the scrapping\\n\\n\")\n",
    "\n",
    "print(\"Converting height and weight to cm and kg...\", end = '')\n",
    "#convert height in df to cm\n",
    "df['Height'] = df['Height'].apply(convertHeightToCm)\n",
    "# convert weight in df to kg\n",
    "df['Weight'] = df['Weight'].apply(convertWeightToKg)\n",
    "print(\"done\\n\\n\")\n",
    "\n",
    "print(\"saving the dataframe to a csv file...\", end = '')\n",
    "df.to_csv('nbaPlayerssAllTimesInfo.csv', index = False)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataframe has 4804 rows and 8 columns\n"
     ]
    }
   ],
   "source": [
    "#get nb rows and nb columns\n",
    "print(\"the dataframe has\", df.shape[0], \"rows and\", df.shape[1], \"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get player Agility infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start of the scrapping\n",
      "........................\n",
      "end of the scrapping\n",
      "\n",
      "\n",
      "saving the dataframe to a csv file...done\n"
     ]
    }
   ],
   "source": [
    "print(\"start of the scrapping\")\n",
    "df = getDataAgilityFromURL(NBA_PLAYERS_AGILITY_URL, 2000, 2023)\n",
    "print(\"\\nend of the scrapping\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"saving the dataframe to a csv file...\", end = '')\n",
    "df.to_csv('nbaPlayersAllTimeAgilityData.csv', index = False)\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PLAYER', 'POS', 'Lane Agility Time (seconds)', 'Shuttle Run (seconds)',\n",
      "       'Three Quarter Sprint (seconds)', 'Standing Vertical Leap (inches)',\n",
      "       'Max Vertical Leap (inches)', 'Max Bench Press (repetitions)'],\n",
      "      dtype='object')\n",
      "           PLAYER POS Lane Agility Time (seconds) Shuttle Run (seconds)  \\\n",
      "0       Max Abmas  PG                       10.90                  3.49   \n",
      "1    Ochai Agbaji  SG                       10.88                  3.10   \n",
      "2   Marcus Bagley  SF                       12.26                  3.10   \n",
      "3  Scottie Barnes  SF                       10.88                  2.99   \n",
      "4  Charles Bassey   C                       12.19                  3.33   \n",
      "\n",
      "  Three Quarter Sprint (seconds) Standing Vertical Leap (inches)  \\\n",
      "0                           3.12                            28.5   \n",
      "1                           3.13                            32.0   \n",
      "2                           3.17                            32.5   \n",
      "3                           3.15                            36.0   \n",
      "4                           3.13                            33.0   \n",
      "\n",
      "  Max Vertical Leap (inches) Max Bench Press (repetitions)  \n",
      "0                       32.5                             -  \n",
      "1                       41.5                             -  \n",
      "2                       38.5                             -  \n",
      "3                       39.5                             -  \n",
      "4                       36.0                             -  \n",
      "the dataframe has 1599 rows and 8 columns\n",
      "the dataframe has 1599 rows and 8 columns\n"
     ]
    }
   ],
   "source": [
    "print(df.keys())\n",
    "print(df.head())\n",
    "print(\"the dataframe has\", df.shape[0], \"rows and\", df.shape[1], \"columns\")\n",
    "\n",
    "#TODO NOT YET WORKING\n",
    "# # remove duplicates where the player name is the same et save recent data\n",
    "# df = df.sort_values(by=['PLAYER'], ascending=False)\n",
    "# df = df.drop_duplicates(subset=['PLAYER'], keep='first')\n",
    "\n",
    "# df size\n",
    "print(\"the dataframe has\", df.shape[0], \"rows and\", df.shape[1], \"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MERGE DATA TEST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data\n",
    "dfStats = pd.read_csv('nbaPlayersAllTimesStatsData.csv')\n",
    "\n",
    "#load the data\n",
    "dfInfo = pd.read_csv('nbaplayerssAllTimesInfo.csv')\n",
    "\n",
    "def formalize(x):\n",
    "    if type(x) == str:\n",
    "        return x.replace(' ', '')\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "#in dfStart remove space in PLAYER columnx\n",
    "dfStats['PLAYER'] = dfStats['PLAYER'].apply(formalize)\n",
    "\n",
    "\n",
    "# merge the two dataframes on Player and PLAYER columns if exist in both\n",
    "df = pd.merge(dfStats, dfInfo, left_on='PLAYER', right_on='Player', how='left')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
